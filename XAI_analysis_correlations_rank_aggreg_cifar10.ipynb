{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "from scipy import stats\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "CSV_DIR = 'csv_merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_method_dict(df, batch = 16):\n",
    "    ''''This function parse the dict and then compute the AUC per image\n",
    "        It returns a dataframe of the shape (Nb_Batch, Nb_images_per_bach)\n",
    "        np.trapz integrates the function under the curve\n",
    "    '''\n",
    "    dataf = pd.DataFrame(columns = [f\"{i}\" for i in range(batch)])\n",
    "    for i in range(df.shape[0]):\n",
    "        row = yaml.safe_load(df.iloc[i].iloc[0])\n",
    "        dataf.loc[i] = [np.trapz(row[j]) for j in row]\n",
    "    #print(dataf)\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_method_dict_with_layers(df, batch = 16):\n",
    "    ''''This function parse the dict and then compute the AUC per image\n",
    "        It returns a dataframe of the shape (Nb_Batch, Nb_images_per_bach)\n",
    "        np.trapz integrates the function under the curve\n",
    "        Note that df.iloc[0] has a dic e.g., {\"layer1\": [list of corr of bacth], \"layer2\": [list of corr of batch]}\n",
    "    '''\n",
    "    dataf = pd.DataFrame(columns = [f\"{i}\" for i in range(batch)])\n",
    "    for i in range(df.shape[0]): # loop over the number of batches\n",
    "        row = yaml.safe_load(df.iloc[i].iloc[0]) # Get the batch result\n",
    "        fillna = lambda v: 0.0 if v == 'nan' else v\n",
    "        # p is the index of image, j is the layer_name, np.trapz computes the AUC\n",
    "        remerged_batch = []\n",
    "        pos = -1\n",
    "        try:\n",
    "            dataf.loc[i] = [np.trapz([fillna(row[j][p]) for j in row]) for p in range(batch)]\n",
    "        except:\n",
    "            last_row = yaml.safe_load(df.iloc[-1].iloc[0])\n",
    "            remerged_batch = [np.trapz([fillna(row[j][p]) for j in row]) for p in range(8)] + [np.trapz([fillna(last_row[j][p]) for j in row]) for p in range(8)]\n",
    "            if pos == -1:\n",
    "                pos = i\n",
    "        if remerged_batch:\n",
    "            dataf.loc[pos] = remerged_batch\n",
    "            dataf = dataf[:-1]\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics =  [\n",
    "    'Model Parameter Randomisation',\n",
    "    'Monotonicity Nguyen',\n",
    "    'Local Lipschitz Estimate',\n",
    "    'Faithfulness Estimate',\n",
    "    'Faithfulness Correlation',\n",
    "    'Avg-Sensitivity',\n",
    "    'Random Logit',\n",
    "    'Max-Sensitivity',\n",
    "    'Sparseness', \n",
    "    'EffectiveComplexity',\n",
    "    'Monotonicity Arya',\n",
    "    'Complexity',\n",
    "    'Pixel-Flipping',\n",
    "    'Selectivity'    \n",
    "]\n",
    "                # ['SensitivityN': problem with implementation,\n",
    "                #'Region Perturbation' seems to be same as region perturbation, \n",
    "                #'Continuity Test': Difficult to aggregate result, the paper just plot it\n",
    "                #'Completeness' always returns False]\n",
    "                # Nonsentitivity is removed\n",
    "\n",
    "metrics_with_different_baselines = {\n",
    "    'Faithfulness Estimate',\n",
    "    'Faithfulness Correlation',\n",
    "    'Monotonicity Arya',\n",
    "    'Monotonicity Nguyen',\n",
    "    'Pixel-Flipping',\n",
    "    'Selectivity',\n",
    "}\n",
    "                \n",
    "baselines = [\n",
    "    'baseline_black',\n",
    "    # 'baseline_mean', not used anymore as there's some probs with quantus implementation\n",
    "    'baseline_random',\n",
    "    'baseline_uniform',\n",
    "    'baseline_white'\n",
    "]\n",
    "\n",
    "transform = {\n",
    "    'Monotonicity Nguyen': lambda x: x.fillna(x.mean()),\n",
    "    'Local Lipschitz Estimate': lambda x: -x, \n",
    "    'Faithfulness Estimate': lambda x: x.fillna(x.mean()),\n",
    "    'Faithfulness Correlation': lambda x: x.fillna(x.mean()),\n",
    "    'Avg-Sensitivity': lambda x: -x,\n",
    "    'Random Logit': lambda x: x.fillna(x.mean()),\n",
    "    'Sparseness': lambda x: x.fillna(x.mean()),\n",
    "    'EffectiveComplexity': lambda x: -x,\n",
    "    'Nonsensitivity': lambda x: -x,\n",
    "    'Pixel-Flipping': lambda x: x.apply(lambda row: - np.trapz(row), axis=1),\n",
    "    'Max-Sensitivity': lambda x: -x,\n",
    "    'Complexity': lambda x: -x.fillna(x.mean()),\n",
    "    'Selectivity': lambda x: -parser_method_dict(x),\n",
    "    'Model Parameter Randomisation': lambda x: -parser_method_dict_with_layers(x),\n",
    "    'Monotonicity Arya': lambda x: x,\n",
    "}\n",
    "\n",
    "aggregate = {\n",
    "    'Monotonicity Nguyen': lambda x: np.tanh(np.mean(np.arctanh(x))),\n",
    "    'Local Lipschitz Estimate': np.mean,\n",
    "    'Faithfulness Estimate': lambda x: np.tanh(np.mean(np.arctanh(x))),\n",
    "    'Faithfulness Correlation': lambda x: np.tanh(np.mean(np.arctanh(x))),\n",
    "    'Avg-Sensitivity': np.mean,\n",
    "    'Random Logit': np.mean,\n",
    "    'Max-Sensitivity': np.mean,\n",
    "    'Sparseness': np.mean, \n",
    "    'EffectiveComplexity': np.mean,\n",
    "    'Monotonicity Arya': np.mean,\n",
    "    'Complexity': np.mean,\n",
    "    'Pixel-Flipping': np.mean,\n",
    "    'Selectivity': np.mean,\n",
    "    'Model Parameter Randomisation': np.mean\n",
    "}\n",
    "\n",
    "methods = ['integratedgrad', 'smoothgrad', 'guidedbackprop', 'rise', 'gradcam',\n",
    "           'scorecam', 'layercam', 'random', 'sobel', 'gaussian', 'polycam',\n",
    "           'cameras']#, 'extremal_perturbation']\n",
    "\n",
    "models = ['resnet50']\n",
    "datasets = ['cifar10']\n",
    "\n",
    "dico_ranks = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET CIFAR10\n",
      "MODEL RESNET50\n",
      "-- Metric: Model Parameter Randomisation\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (1984) does not match length of index (2000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8504/257657681.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3654\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \"\"\"\n\u001b[0;32m-> 3832\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4535\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4536\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1984) does not match length of index (2000)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8504/257657681.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrankdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0maverage_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3653\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3830\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \"\"\"\n\u001b[0;32m-> 3832\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3834\u001b[0m         if (\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4535\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4536\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \"\"\"\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1984) does not match length of index (2000)"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(f'DATASET {dataset.upper()}')\n",
    "    dico_ranks[dataset] = {}\n",
    "    for model in models:\n",
    "        print(f'MODEL {model.upper()}')\n",
    "        dico_ranks[dataset][model] = {}\n",
    "        for metr in metrics:\n",
    "            if metr in metrics_with_different_baselines and model == 'resnet50' and dataset == 'imagenet':\n",
    "                for baseline in baselines:\n",
    "                    metr_with_baseline = f'{metr} with {baseline}'\n",
    "                    print(f\"-- Metric: {metr_with_baseline}\")\n",
    "                    data = pd.DataFrame()\n",
    "                    for meth in methods:\n",
    "                        if meth == 'cameras' or meth == 'extremal_perturbation':\n",
    "                            csv_name = f\"{CSV_DIR}/{meth}_{model}_{dataset}_{metr}.csv\"\n",
    "                        else:\n",
    "                            csv_name = f\"{CSV_DIR}/{meth}_{model}_{dataset}_{metr}_{baseline}.csv\"\n",
    "                        df = pd.read_csv(csv_name, header = None)\n",
    "                        data[meth] = transform[metr](df).values.flatten()[:2000]\n",
    "                        scores.append(-aggregate[metr](data))\n",
    "                    ranks = np.array([rankdata(-p) for p in data.values])\n",
    "                    average_ranks = np.mean(ranks, axis=0)\n",
    "                    dico_ranks[dataset][model][metr_with_baseline] = average_ranks\n",
    "            else:\n",
    "                print(f\"-- Metric: {metr}\")\n",
    "                data = pd.DataFrame()\n",
    "                for meth in methods:\n",
    "                    csv_name = f\"{CSV_DIR}/{meth}_{model}_{dataset}_{metr}.csv\"\n",
    "                    df = pd.read_csv(csv_name, header = None)\n",
    "                    try:\n",
    "                        data[meth] = transform[metr](df).values.flatten()[:2000]\n",
    "                    except:\n",
    "                        data[meth] = transform[metr](df).values.flatten()\n",
    "                ranks = np.array([rankdata(-p) for p in data.values])\n",
    "                average_ranks = np.mean(ranks, axis=0)\n",
    "                dico_ranks[dataset][model][metr] = average_ranks\n",
    "        print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = transform[metr](df).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1984,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rankings_by_rank_aggreg_cifar10.pickle', 'wb') as file:\n",
    "    pickle.dump(dico_ranks, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rankings_by_rank_aggreg_cifar10.pickle', 'rb') as file:\n",
    "    dico_ranks = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kendall_w(dico_ranks, metrics):\n",
    "    rankings = [rankdata(dico_ranks[metric]) for metric in metrics]\n",
    "    data = []\n",
    "    for i in range(len(rankings[0])):\n",
    "        data.append([rankings[j][i] for j in range(len(rankings))])   \n",
    "    \n",
    "    # source of the implementation : https://github.com/ugolbck/kendall-w/blob/master/kendall_w/kendall_w.py\n",
    "    m = len(data[0])\n",
    "    n = len(data)\n",
    "    sums = [sum(x) for x in data]\n",
    "    Rbar = sum(sums) / n\n",
    "    S = sum([(sums[x] - Rbar) ** 2 for x in range(n)])\n",
    "    W = (12 * S) / (m ** 2 * (n ** 3 - n))\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kendall_tau(dico_ranks, metrics):\n",
    "    tau_values = []\n",
    "    p_values = []\n",
    "\n",
    "    for metric_a in metrics:\n",
    "        current_tau_values = []\n",
    "        current_p_values = []\n",
    "        for metric_b in metrics:\n",
    "            tau, p_value = stats.kendalltau(dico_ranks[metric_a], dico_ranks[metric_b])\n",
    "            current_tau_values.append(tau)\n",
    "            current_p_values.append(p_value)\n",
    "        tau_values.append(current_tau_values)\n",
    "        p_values.append(current_p_values)\n",
    "        \n",
    "    return tau_values, p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_matrix_figure(dico_ranks, metrics, y_labels, x_labels, filename, fig_size, rotate_x=True, half_rotate_x=False, rotate_y=True, subgroups=None):\n",
    "    tau_values, p_values = compute_kendall_tau(dico_ranks, metrics)\n",
    "    \n",
    "    p_values_flattened = [p_value for i, sublist in enumerate(p_values) for p_value in sublist[:i]]\n",
    "    reject, _, _, _ = multipletests(p_values_flattened, alpha=0.05, method='holm')\n",
    "\n",
    "    sn.set(rc={'figure.figsize': fig_size})\n",
    "\n",
    "    p_values_flattened = [p_value for i, sublist in enumerate(p_values) for p_value in sublist[:i]]\n",
    "    reject, _, _, _ = multipletests(p_values_flattened, alpha=0.05, method='holm')\n",
    "    mask = np.ones((len(metrics),len(metrics)), dtype=bool)\n",
    "    current_post = 0\n",
    "    for i in range(len(metrics)):\n",
    "        for j in range(i):\n",
    "            mask[i][j] = reject[current_post]\n",
    "            mask[j][i] = reject[current_post]\n",
    "            current_post += 1\n",
    "\n",
    "    sn.heatmap(tau_values,\n",
    "               annot=True,\n",
    "               vmin=-1,\n",
    "               vmax=1,\n",
    "               cbar=False,\n",
    "               xticklabels=x_labels,\n",
    "               yticklabels=y_labels,\n",
    "               mask=mask,\n",
    "               cmap='viridis')\n",
    "\n",
    "    mask = np.ones((len(metrics),len(metrics)), dtype=bool)\n",
    "    current_post = 0\n",
    "    for i in range(len(metrics)):\n",
    "        for j in range(i):\n",
    "            mask[i][j] = not reject[current_post]\n",
    "            mask[j][i] = not reject[current_post]\n",
    "            current_post += 1\n",
    "        mask[i][i] = False\n",
    "\n",
    "    ax = sn.heatmap(tau_values,\n",
    "                    annot=True,\n",
    "                    annot_kws={\"style\": \"italic\", \"weight\": \"bold\"},\n",
    "                    vmin=-1,\n",
    "                    vmax=1,\n",
    "                    cbar=False,\n",
    "                    xticklabels=x_labels,\n",
    "                    yticklabels=y_labels,\n",
    "                    mask=mask,\n",
    "                    cmap='viridis')\n",
    "\n",
    "    if half_rotate_x:\n",
    "        plt.xticks(rotation=20, ha=\"right\")\n",
    "    elif rotate_x:\n",
    "        plt.xticks(rotation=0)\n",
    "    if rotate_y:\n",
    "        plt.yticks(rotation=0)\n",
    "    \n",
    "    start_i = 0\n",
    "    if subgroups:\n",
    "        for subgroup_size in subgroups:\n",
    "            ax.add_patch(Rectangle((start_i, start_i), subgroup_size, subgroup_size, fill=False, edgecolor='crimson', lw=4, clip_on=False))\n",
    "            start_i += subgroup_size\n",
    "    \n",
    "    plt.savefig(f'./results/{filename}.eps', bbox_inches='tight', format='eps')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print('RESULTS')\n",
    "    print(f\"Kendall's W: {compute_kendall_w(dico_ranks, metrics)}\")\n",
    "    print(\"Kendall's Tau:\")\n",
    "    for i, metric_a in enumerate(metrics):\n",
    "        for j, metric_b in enumerate(metrics):\n",
    "            if i < j:\n",
    "                print(f'{metric_a} / {metric_b} : {tau_values[i][j]} ({p_values[i][j]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures and results for article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 (Cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranks = pd.DataFrame(dico_ranks['cifar10']['resnet50'], index= methods)\n",
    "metrics_with_baselines = sorted(dico_ranks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness with black baseline and different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metrics = ['Faithfulness Correlation','Faithfulness Estimate','Monotonicity Arya','Monotonicity Nguyen','Pixel-Flipping','Selectivity']\n",
    "labels = ['Faithfulness Correlation (FC)','Faithfulness Estimate (FE)','Monotonicity Arya (MA)','Monotonicity Nguyen (MN)','Pixel-Flipping (PF)','Selectivity (Se)']\n",
    "short_labels = ['FC','FE', 'MA','MN','PF','Se']\n",
    "filename = 'rebuttal_final_corr_matrix_rank_aggreg_holm_corr_faithfulness_resnet50_cifar10'\n",
    "plot_corr_matrix_figure(dico_ranks['cifar10']['resnet50'], selected_metrics, short_labels, short_labels, filename, fig_size=(5,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metrics = ['Complexity','EffectiveComplexity','Sparseness']\n",
    "labels = ['Complexity (C)', 'Effective Complexity (E)', 'Sparseness (S)']\n",
    "short_labels = ['C','E', 'S']\n",
    "filename = 'final_corr_matrix_rank_aggreg_holm_corr_complexity_resnet50_cifar10'\n",
    "plot_corr_matrix_figure(dico_ranks['cifar10']['resnet50'], selected_metrics, short_labels, short_labels, filename, fig_size=(2,1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metrics = ['Model Parameter Randomisation', 'Random Logit']\n",
    "labels = ['Model Parameter Randomisation (M)', 'Random Logit (R)']\n",
    "short_labels = ['M','R']\n",
    "filename = 'final_corr_matrix_rank_aggreg_holm_corr_randomization_resnet50_cifar10'\n",
    "plot_corr_matrix_figure(dico_ranks['cifar10']['resnet50'], selected_metrics, short_labels, short_labels, filename, fig_size=(1.5,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metrics = ['Avg-Sensitivity','Local Lipschitz Estimate', 'Max-Sensitivity']\n",
    "labels = ['Avg-Sensitivity (A)', 'Local Lipschitz Estimate (L)', 'Max-Sensitivity (M)']\n",
    "short_labels = ['A','L', 'M']\n",
    "filename = 'final_corr_matrix_rank_aggreg_holm_corr_robustness_resnet50_cifar10'\n",
    "plot_corr_matrix_figure(dico_ranks['cifar10']['resnet50'], selected_metrics, short_labels, short_labels, filename, fig_size=(2,1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All metrics with default baselines (i.e. black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metrics =  [\n",
    "    'Complexity',\n",
    "    'EffectiveComplexity',\n",
    "    'Sparseness',\n",
    "    'Model Parameter Randomisation',\n",
    "    'Random Logit',   \n",
    "    'Avg-Sensitivity',\n",
    "    'Local Lipschitz Estimate',\n",
    "    'Max-Sensitivity',\n",
    "    'Faithfulness Correlation',\n",
    "    'Faithfulness Estimate',\n",
    "    'Monotonicity Arya',\n",
    "    'Monotonicity Nguyen',\n",
    "    'Pixel-Flipping',\n",
    "    'Selectivity'    \n",
    "]\n",
    "\n",
    "labels = [\n",
    "    'Complexity',\n",
    "    'EffectiveComplexity',\n",
    "    'Sparseness',\n",
    "    'Model Parameter Randomisation',\n",
    "    'Random Logit',   \n",
    "    'Avg-Sensitivity',\n",
    "    'Local Lipschitz Estimate',\n",
    "    'Max-Sensitivity',\n",
    "    'Faithfulness Correlation',\n",
    "    'Faithfulness Estimate',\n",
    "    'Monotonicity Arya',\n",
    "    'Monotonicity Nguyen',\n",
    "    'Pixel-Flipping',\n",
    "    'Selectivity'    \n",
    "]\n",
    "\n",
    "#for metric in metrics:\n",
    "#    if metric in metrics_with_different_baselines:\n",
    "#        selected_metrics.append(f'{metric} with baseline_black')\n",
    "#    elif metr == 'Model Parameter Randomisation':\n",
    "#        metr_with_baseline = f'{metr} with bottom_up'\n",
    "#        final_dico_ranks[metr] = dico_ranks[metr_with_baseline]\n",
    "#    else:\n",
    "#        selected_metrics.append(metric)\n",
    "#    labels.append(metric)\n",
    "\n",
    "# selected_metrics.sort()\n",
    "# labels.sort()\n",
    "filename = 'final_corr_matrix_rank_aggreg_holm_corr_all_metrics_default_baselines_resnet50_cifar10'\n",
    "plot_corr_matrix_figure(dico_ranks['cifar10']['resnet50'], selected_metrics, labels, labels, filename, fig_size=(10,8), rotate_x=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_corr_matrix_rank_aggreg_holm_corr_all_metrics_default_baselines_with_subgroups_resnet50_cifar10'\n",
    "plot_corr_matrix_figure(dico_ranks['cifar10']['resnet50'], selected_metrics, labels, labels, filename, fig_size=(10,8), half_rotate_x=True, subgroups=(3,2,3,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All metrics with all baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metrics = sorted(dico_ranks['cifar10']['resnet50'].keys())\n",
    "filename = 'final_corr_matrix_rank_aggreg_holm_corr_all_metrics_all_baselines_resnet50_cifar10'\n",
    "plot_corr_matrix_figure(dico_ranks['cifar10']['resnet50'], selected_metrics, selected_metrics, selected_metrics, filename, fig_size=(23.4,16.54), rotate_x=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
